{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b65ae36-a022-4d70-8cdf-8247653bb94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b7edf71-1622-4d8d-afe6-75e33ac3d006",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jupyter_ai_magics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjupyter_ai_magics\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Andela\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2456\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2454\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2455\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2456\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2458\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2459\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2460\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2461\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Andela\\Lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mextension_manager\u001b[38;5;241m.\u001b[39mload_extension(module_str)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Andela\\Lib\\site-packages\\IPython\\core\\extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_extension(module_str)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Andela\\Lib\\site-packages\\IPython\\core\\extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m---> 91\u001b[0m         mod \u001b[38;5;241m=\u001b[39m import_module(module_str)\n\u001b[0;32m     92\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module_str]\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Andela\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'jupyter_ai_magics'"
     ]
    }
   ],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "618410f6-f4b6-4bb8-9c59-52e54650c79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e942474-4253-4189-aa72-fc46e112b5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b06624-18c3-4da8-b0af-fcad4aaee432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b4a7429-1ad4-43eb-95dc-5b92557e00c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0517327-9ecc-4250-988d-cdaf37cf2e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: %%ai [OPTIONS] MODEL_ID\n",
      "\n",
      "  Invokes a language model identified by MODEL_ID, with the prompt being\n",
      "  contained in all lines after the first. Both local model IDs and global\n",
      "  model IDs (with the provider ID explicitly prefixed, followed by a colon)\n",
      "  are accepted.\n",
      "\n",
      "  To view available language models, please run `%ai list`.\n",
      "\n",
      "Options:\n",
      "  -f, --format [code|html|image|json|markdown|math|md|text]\n",
      "                                  IPython display to use when rendering\n",
      "                                  output. [default=\"markdown\"]\n",
      "  -n, --region-name TEXT          AWS region name, e.g. 'us-east-1'. Required\n",
      "                                  for SageMaker provider; does nothing with\n",
      "                                  other providers.\n",
      "  -q, --request-schema TEXT       The JSON object the endpoint expects, with\n",
      "                                  the prompt being substituted into any value\n",
      "                                  that matches the string literal '<prompt>'.\n",
      "                                  Required for SageMaker provider; does\n",
      "                                  nothing with other providers.\n",
      "  -p, --response-path TEXT        A JSONPath string that retrieves the\n",
      "                                  language model's output from the endpoint's\n",
      "                                  JSON response. Required for SageMaker\n",
      "                                  provider; does nothing with other providers.\n",
      "  -m, --model-parameters TEXT     A JSON value that specifies extra values\n",
      "                                  that will be passed to the model. The\n",
      "                                  accepted value parsed to a dict, unpacked\n",
      "                                  and passed as-is to the provider class.\n",
      "  --help                          Show this message and exit.\n",
      "------------------------------------------------------------------------------\n",
      "Usage: %ai [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  Invokes a subcommand.\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  delete    Delete an alias. See `%ai delete --help` for options.\n",
      "  error     Explains the most recent error.\n",
      "  help      Show this message and exit.\n",
      "  list      List language models. See `%ai list --help` for options.\n",
      "  register  Register a new alias. See `%ai register --help` for options.\n",
      "  update    Update the target of an alias. See `%ai update --help` for\n",
      "            options.\n",
      "  version   Prints Jupyter-AI version\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%ai help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d61d93d-1578-442d-8e02-c5ea60e73daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li><li>`bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0`</li></ul> |\n",
       "| `azure-chat-openai` | `AZURE_OPENAI_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li></ul> |\n",
       "| `gemini` | `GOOGLE_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`gemini:gemini-1.0-pro`</li><li>`gemini:gemini-1.0-pro-001`</li><li>`gemini:gemini-1.0-pro-latest`</li><li>`gemini:gemini-1.0-pro-vision-latest`</li><li>`gemini:gemini-pro`</li><li>`gemini:gemini-pro-vision`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-0125`</li><li>`openai-chat:gpt-3.5-turbo-0301`</li><li>`openai-chat:gpt-3.5-turbo-0613`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-3.5-turbo-16k`</li><li>`openai-chat:gpt-3.5-turbo-16k-0613`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-turbo-preview`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-32k`</li><li>`openai-chat:gpt-4-32k-0613`</li><li>`openai-chat:gpt-4-0125-preview`</li><li>`openai-chat:gpt-4-1106-preview`</li></ul> |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "| `togetherai` | `TOGETHER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`togetherai:Austism/chronos-hermes-13b`</li><li>`togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2`</li><li>`togetherai:EleutherAI/llemma_7b`</li><li>`togetherai:Gryphe/MythoMax-L2-13b`</li><li>`togetherai:Meta-Llama/Llama-Guard-7b`</li><li>`togetherai:Nexusflow/NexusRaven-V2-13B`</li><li>`togetherai:NousResearch/Nous-Capybara-7B-V1p9`</li><li>`togetherai:NousResearch/Nous-Hermes-2-Yi-34B`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-13b`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-70b`</li></ul> |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable: AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:cohere.command-light-text-v14\n",
       "* bedrock:cohere.command-text-v14\n",
       "* bedrock:meta.llama2-13b-chat-v1\n",
       "* bedrock:meta.llama2-70b-chat-v1\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-v2:1\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "* bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0\n",
       "\n",
       "azure-chat-openai\n",
       "Requires environment variable: AZURE_OPENAI_API_KEY (not set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "cohere\n",
       "Requires environment variable: COHERE_API_KEY (not set)\n",
       "* cohere:command\n",
       "* cohere:command-nightly\n",
       "* cohere:command-light\n",
       "* cohere:command-light-nightly\n",
       "\n",
       "gemini\n",
       "Requires environment variable: GOOGLE_API_KEY (set)\n",
       "* gemini:gemini-1.0-pro\n",
       "* gemini:gemini-1.0-pro-001\n",
       "* gemini:gemini-1.0-pro-latest\n",
       "* gemini:gemini-1.0-pro-vision-latest\n",
       "* gemini:gemini-pro\n",
       "* gemini:gemini-pro-vision\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "* gpt4all:mistral-7b-openorca.Q4_0\n",
       "* gpt4all:mistral-7b-instruct-v0.1.Q4_0\n",
       "* gpt4all:gpt4all-falcon-q4_0\n",
       "* gpt4all:wizardlm-13b-v1.2.Q4_0\n",
       "* gpt4all:nous-hermes-llama2-13b.Q4_0\n",
       "* gpt4all:gpt4all-13b-snoozy-q4_0\n",
       "* gpt4all:mpt-7b-chat-merges-q4_0\n",
       "* gpt4all:orca-mini-3b-gguf2-q4_0\n",
       "* gpt4all:starcoder-q4_0\n",
       "* gpt4all:rift-coder-v0-7b-q4_0\n",
       "* gpt4all:em_german_mistral_v01.Q4_0\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable: HUGGINGFACEHUB_API_TOKEN (not set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai:babbage-002\n",
       "* openai:davinci-002\n",
       "* openai:gpt-3.5-turbo-instruct\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-0125\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "* openai-chat:gpt-3.5-turbo-0613\n",
       "* openai-chat:gpt-3.5-turbo-1106\n",
       "* openai-chat:gpt-3.5-turbo-16k\n",
       "* openai-chat:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-turbo-preview\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0613\n",
       "* openai-chat:gpt-4-0125-preview\n",
       "* openai-chat:gpt-4-1106-preview\n",
       "\n",
       "qianfan\n",
       "Requires environment variables: QIANFAN_AK (not set), QIANFAN_SK (not set)\n",
       "* qianfan:ERNIE-Bot\n",
       "* qianfan:ERNIE-Bot-4\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "togetherai\n",
       "Requires environment variable: TOGETHER_API_KEY (not set)\n",
       "* togetherai:Austism/chronos-hermes-13b\n",
       "* togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2\n",
       "* togetherai:EleutherAI/llemma_7b\n",
       "* togetherai:Gryphe/MythoMax-L2-13b\n",
       "* togetherai:Meta-Llama/Llama-Guard-7b\n",
       "* togetherai:Nexusflow/NexusRaven-V2-13B\n",
       "* togetherai:NousResearch/Nous-Capybara-7B-V1p9\n",
       "* togetherai:NousResearch/Nous-Hermes-2-Yi-34B\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-13b\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-70b\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:davinci-002\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "ernie-bot - qianfan:ERNIE-Bot\n",
       "ernie-bot-4 - qianfan:ERNIE-Bot-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae32285b-6701-4678-8d65-ff27735abf71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Lists:\n",
       "\n",
       "- Mutable\n",
       "- Ordered\n",
       "- Allows duplicates\n",
       "- Can contain different data types\n",
       "- Can be modified using methods like append, insert, remove, etc.\n",
       "\n",
       "Tuples:\n",
       "\n",
       "- Immutable\n",
       "- Ordered\n",
       "- Allows duplicates\n",
       "- Can contain different data types\n",
       "- Cannot be modified once created\n",
       "\n",
       "Sets:\n",
       "\n",
       "- Mutable\n",
       "- Unordered\n",
       "- Does not allow duplicates\n",
       "- Only contains unique elements\n",
       "- Can be modified using methods like add, remove, etc."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai openai-chat:gpt-3.5-turbo\n",
    "lists vs. tuples vs. sets in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc8ea7-3ab4-4fef-a8b3-a15ee0e4f75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
